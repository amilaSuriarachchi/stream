\section{Conclusions and Future Work}
In this paper we have described our approach to achieving high-throughput multi-stage stream processing.  We have used application message buffering to improve serialization and deserialization process and thread pools to improve parallelism.

We have validated the soundness of our methodology using empirical benchmarks that contrast its performance with well-known systems such as Twitter Storm \cite{toshniwal2014storm} and Yahoo S4\cite{neumeyer2010s4}. Our approach allows cumulative throughputs that significantly outperform these aforementioned systems. In a two stage setting we are able to achieve a processing throughput of 2.3 million messages per-second and a network utilization of 95\% (950Mbps/1Gbps) even with one receiver. In a four-stage setting we are able to achieve a processing throughput of 2.5 million messages per-second and a network utilization of 98\% (982Mbps/1Gbps) with four receiving units.

Our future work will mainly target two areas: reliable message delivery and compression. We will focus on implementing a reliable message delivery protocol to support at least one guarantee on top of our communication framework.  The work on compression will target reducing the overthe-wire footprints of the packets. We will explore the use of compression algorithms while ensuring that the gains in message size reduction do not result in unacceptable latency overheads and also that the throughput improves. 

