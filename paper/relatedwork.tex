\section{Related Work}
Much of the inspiration for stream processing systems can be trace back to data stream management systems. These systems support a window based query language. Most of these languages are derived from SQL, for instance STREAM \cite{arasu2004stream} defines a language called \textit{Continuous Query Language(CQL)} which has similar syntactic characteristics as SQL. Aurora \cite{abadi2003aurora}, STREAM \cite{arasu2004stream} and Nile \cite{hammad2004nile} are some of the prominent implementations of DSMSs. Complex event processing(CEP) systems such as Esper \cite{esper}, Siddhi \cite{suhothayan2011siddhi}, Cayuga \cite{brenna2007cayuga} also share many characteristics with DSMSs except for their use cases. CEP systems are capable of handling multiple incoming event streams(which are similar to the input streams) and identifying patterns across streams which are of interest to the end users. However these systems do not support user defined logic and hence not suitable for implement complex logic based on machine learning techniques. 

MapReduce \cite{dean2008mapreduce} is a widely used to process batch data. Apache Hadoop \cite{hadoop} is a widely used implementation of MapReduce. In a MapReduce environment a problem is partitioned into smaller parts identified by a key and process parallely. Although these systems support user defined functions, data processing flow of these systems are fixed. Ciel \cite{murray2011ciel} address this problem by dynamically generating data flow graph. Since all these systems communicate through file system they inherently not suitable for real time processing \cite{lam2012muppet}. 

Stream Processing Core (SPC) \cite{Amini2006}, Yahoo S4 \cite{neumeyer2010s4} and Twitter Storm \cite{twitterStorm} address the above issue by supporting direct communication. These systems are based on the Actor model \cite{agha1985actors} and each system has a notion of processing element or computation. Processing Elements are used to perform user defined logic on the receiving events and emit newly generated events to other processing elements. In addition to basic communication these systems provide fault tolerance features such as reliable message delivery and dynamic membership management. However most of these systems do not focus on improving inter node communication performance.

Spark \cite{zaharia2010spark} introduces its RRDs \cite{zaharia2012resilient} to achieve better fault tolerance by storing the operations and replaying them instead of replicating data itself or use checkpointing to store data periodically. Spark Streaming \cite{zaharia2013discretized} extends this concept to distributed stream processing with the concept of discretized events. Spark streaming \cite{zaharia2013discretized} processes data as batches while storing them as RDDs \cite{zaharia2012resilient} to achieve higher throughput. This batch processing may introduce latencies which are not acceptable for some applications. Further it is not clear how to implement complex event processing algorithms such as we use our benchmarks with Spark Streaming. MillWheel \cite{akidau2013millwheel} is the stream processing system used at Google to process web queries. MillWheel \cite{akidau2013millwheel} provides reliable message processing as well as state persistence for its graph based computations. Unlike our system, MillWheel treats messages as binary messages leaving message parsing and serialization to the application layer. 
