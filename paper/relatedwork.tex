\section{Related Work}
Much of the inspiration for stream processing systems can be trace back to data stream management systems. These systems support a window based query language. Most of these languages are derived from SQL, for instance STREAM\cite{arasu2004stream} defines a language called \textit{Continuous Query Language(CQL)} which has similar syntactic characteristics as SQL. Aurora\cite{abadi2003aurora}, STREAM\cite{arasu2004stream} and Nile\cite{hammad2004nile} are some of the prominent implementations of DSMSs. Complex event processing(CEP) systems such as Esper\cite{esper}, Siddhi\cite{suhothayan2011siddhi}, Cayuga\cite{brenna2007cayuga} also share many characteristics with DSMSs except for their use cases. CEP systems are capable of handling multiple incoming event streams(which are similar to the input streams) and identifying patterns across streams which are of interest to the end users. However these systems does not support user defined logic and hence not suitable for implement complex logic based on machine 
learning techniques. 

Map reduce\cite{dean2008mapreduce} is a widely adapted technology to process batch data with the populariy of Apache Hadoop\cite{hadoop}. In a map reduce envirionment a problem is partition into smaller parts identified by a key and process parallely. Although these systems support user defined functions, data processing flow of these systems are fixed. Ciel\cite{murray2011ciel} address this problem by dynamically generating dataflow graph. Since all these systems communicate through file system they inherently not suitable for real time processing\cite{lam2012muppet}. 

Stream Processing Core (SPC)\cite{Amini2006}, Yahoo S4\cite{neumeyer2010s4} and Twitter Storm\cite{twitterStorm} address the above issue by supporting direct communication. These systems are based on the Actor model\cite{agha1985actors} and each system has a notion of processing element or computation. Processing Elements are used to perform user defined logic on the receiving events and emit newly generated events to other processing elements. In addition to basic communication these systems provide fault tolarance features such as relaiable message delivary and dynamic membership management. However most of these system does not focus on improving internode communication performance.

Spark\cite{zaharia2010spark} introduces its RRDs\cite{zaharia2012resilient} to achive better fault tolarance by storing the operations and replaying them instead of replicating data itself or use checkpointing to store data periodically. Spark Streaming\cite{zaharia2013discretized} extends this concept to distributed stream processing with the concept of discretized events. Spark streaming\cite{zaharia2013discretized} processes data as batches while storing them as RDDs \cite{zaharia2012resilient} to achive higher throughput. This batch processing may introduce latances which are not acceptable for some applications. Further it is not clear how to implement complex event processing algorithumns such as we use our bench marks with Spark Streaming. MillWheel\cite{akidau2013millwheel} is the stream processing system used at Google to process web queries. MillWheel\cite{akidau2013millwheel} provides relaiable message processing as well as state persistance for its graph based computations. Unlike in our system MillWheel treat messages as binary 
messages leaving message parsing and serialization to application layer. 
