\section{Experiments}

We conducted several performance tests to measure the throughput and scalability of our system. All these tests were performed in an LAN system called Lattice which has a network bandwidth of 1Gbps. All nodes are Intel(R) Xeon(R) 2.4GHz 4 core duo machines with 1 Gbp of memory. We used Apache S4 0.6.0 version and Apache storm 0.9.2 version. Sample code used for all tests can be found here\cite{solutionCode}.


\subsection{Inter node communication}
We used a graph as shown in Figure \ref{ecgGraph} to process ECG signal data. Our solution and Yahoo S4\cite{neumeyer2010s4} \textit{EventProducer} reads a file containing over 7500000 ecg records and pushes events with multiple threads. Twitter Storm\cite{twitterStorm} does not allow user threads to push data. So we used the \textit{spout} thread to send messages into the system. \textit{EventReceiver}  receives the ECG events, process them and calculate heart rate interval periodically.  
\subsubsection{Throughput}
We executed our system with 1, 2 and 4  \textit{EventReceivers} for each system and measured the throughput, load average and network bandwidth  for each case. Throughput was measured at the \textit{EventProducer} by calculating the total time required to send messages and the total number of messages send. Load average and network bandwidth were measured using top and atop linux commands respectively. Figure \ref{throuput} shows the throughput variation with the number of nodes for all systems. 

\begin{figure}[!t]
        \centering
        \includegraphics[width=3.0in]{ecgGraph.png}
        \caption{ECG Process Graph}
        \label{ecgGraph}
\end{figure}
\begin{figure}[!t]
        \centering
        \includegraphics[width=3.0in]{throughput.png}
        \caption{Throughput of the systems}
        \label{throuput}
\end{figure}

As shown in the Figure \ref{throuput} our solution outperforms Twitter storm\cite{twitterStorm} and Yahoo S4\cite{neumeyer2010s4}. However by looking the Figure \ref{throuput} one might think even our solution is not scalable although it performs high. In order to examine the reason behind this we looked into the network bandwidth and CPU load average values. 
 
Figure \ref{networkandload} shows the network bandwidth usage and the CPU load average at each node. For multiple node scenarios we observed the same values for bandwidth usage and CPU load average at each receiver. Therefore we have taken the average values of them. 

\begin{figure*}[!t]
	\centering
	\subfloat[Network Usage]{\includegraphics[width=3.0in]{network.png}}
	\hfil
	\subfloat[CPU Load Average]{\includegraphics[width=3.0in]{loadaverage.png}}
	\caption{Network usage and CPU Load Average of the System}
	\label{networkandload}
\end{figure*}
 

By looking at the graphs, first it can be observed that our solution utilities all available network bandwidth (98\%) even with two receivers. In only one receiver case, high CPU load average at receiver indicates it has utilized available CPU power. Adding two receivers has increased the CPU power at receiving side utilizing all available network bandwidth. Therefore it can not increase the throughput without increasing network bandwidth although more CPU power is available at receiver nodes. Having receiver nodes, we can observe that network bandwidth and CPU load average is reduced at each receiver, since load is shared among the receivers. However for other two systems, it neither hits the maximum network bandwidth available nor the full CPU power available at any stage. If a system does not make use of the available resources then adding more resources won't scale up the system. As explained in earlier, our solution utilities all available resources by using parallel tcp connections and having an efficient 
message parse technique.

\subsubsection{Efficiency of Message Serialization}
After measuring the throughput we examined the  total amount of extra bytes each system sends to transfer the information from \textit{EventProducer} to \textit{EventReceiver}. Our ECGEvent has two double fields called time and value (ecg signal value) and a streamID which is a 4 byte string. So we calculated total bytes to send this information as 20 bytes (16 for two doubles and 4 for streamID). Then by using the throughput and the bandwidth usage of the system we calculated the total number of bytes each system uses at network layer to send this message. By reducing 20 information bytes we calculated the overhead bytes for each system. Figure \ref{efficiency} compares these numbers.

\begin{figure}[!t]
        \centering
        \includegraphics[width=3.0in]{efficiency.png}

        \caption{Efficiency of Message Serialization}
        \label{efficiency}
\end{figure}

As shown in the figure \ref{efficiency} Twitter storm\cite{twitterStorm} uses a minimum over head while Yahoo S4\cite{neumeyer2010s4} performs badly compared to other two. This overhead is due to its usage of  java serialization to serialize data. Then we analyzed for what our solution spends extra 32 bytes. Our solution adds a sequence number (an integer), receiving process id (a 8 byte string for this scenario), sending process id (a 8 byte string for this scenario) to order messages, dispatch the message to correct process and to parse the message at the server. Altogether it adds 26 (serialization format of a string uses two more bytes to keep the string length) extra bytes to each message at application level and another 4 bytes due to tcp overhead. This is the trade off we had to pay to improve the parallelism compared to direct one tcp communication per process. 

\subsubsection{Latency}
We examined the message latency between the event producer and receiver. For this experiment we sent the timestamp at the producer along the message and calculated the latency at the receiver. We took 6000 samples over experiment duration. As shown in the figure \ref{latancydis}, we could observe the mean latency as 185.05 with the 95\% confidence interval of (182.56 187.54). 

\begin{figure*}[!t]
        \centering
        \subfloat[Histogram]{\includegraphics[width=3.0in]{latencyHistogram.png}}
        \hfil
        \subfloat[Box Plot]{\includegraphics[width=3.0in]{latencyBoxPlot.png}}
        \caption{Message Latency Distribution}
        \label{latancydis}
\end{figure*}


\subsection{Scalability}
We performed a scalability test for our system using the 3 level graph shown in Figure \ref{multigraph}. The processing data as well as the processing logic were obtained from the grand challenge problem of 8th ACM international conference on distributed event based systems. We used the publicly available 500MB of data to generate the events. 

\begin{figure}[!t]
        \centering
        \includegraphics[width=3.0in]{multigraph.png}
        \caption{Multilevel Node Graph}
        \label{multigraph}
\end{figure}

This application predicts load averages using previous values and a machine learning algorithm. We implemented this logic using nodes as shown in the Figure \ref{multigraph}. First producer reads the data file and send events to the \textit{avgCal} node which calculates the last minute average and sends the same event to both \textit{plugPredict} and \textit{housePredict} processors. Both \textit{plugPredict} and \textit{housePredict} processors predict the next values and send events to receivers. The original problem only requires to send those prediction events in 30s intervals. But we used a prediction event for each messages to observe how the system works with high load.
 
As in the earlier case, we conducted our experiments using one producer and multiplying the other processing nodes by 1, 2 and 4 times to measure the throughput increase at the producer. We ran each node in a separate machine so that our receiver configurations used 5, 10, 15 machines respectively. We measured the throughput,  network bandwidth and the CPU load average at the producer to examine the scalability of the system. Since the one receiver unit throughput greater than that of the storm one node scenario, we only used our system for this experiment.  Results are shown in the Figure \ref{scalability}.


\begin{figure*}[!t]
        \centering
        \subfloat[Throughput]{\includegraphics[width=3.0in]{throughputs.png}}
        \hfil
        \subfloat[Network Usage]{\includegraphics[width=3.0in]{networkps.png}}
        \hfil
        \subfloat[Network Usage Bandwidth]{\includegraphics[width=3.0in]{networks.png}}
        \hfil
        \subfloat[CPU Load Average]{\includegraphics[width=3.0in]{loadaverages.png}}
        \caption{Scalability of the System}
        \label{scalability}
\end{figure*}


For one receiver unit case, we observed very high load average and network bandwidth usage at \textit{avgCal} node since it sends messages to two nodes. Then as shown in the figure \ref{scalability} we could linearly scale up the system by adding more receiver units to add more cpu power to the system. When increasing the receiver units, we could observe throughput of the system increases proportional to number of receiving units. CPU load average of 13 at the producer indicates it has utilized all available CPU power and it is required to add more producers to scale this system further up. 


