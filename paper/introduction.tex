\section{Introduction}

Multi-stage, distributed stream processing is useful in analyzing data streams generated by programs, sensors, or users in real time. Analysis of click-streams, tweets, and stock-quotes are primary examples where such processing is often performed. Most commonly, in such systems packets encapsulate tuples representing values corresponding to a set of variables. 

These systems receive billions of tuples daily expecting results within fractions of second. Hence these systems are required to process data with high throughput and low latency. The processing logic of these systems are expressed as multi stage graphs and deployed into clusters of hundreds of commodity machines. Each stage receive messages from the previous stage, process them according to a user defined logic and forward them to next stage. Therefore performance of the inter node communication make a huge impact of overall system performance.  

Apart from these primary requirements, other features such as reliable message delivery,  state preservation and load balancing are also required depending on the nature of the high level applications. There have been many frameworks \cite{toshniwal2014storm} \cite{zaharia2010spark} \cite{akidau2013millwheel} \cite{murray2013naiad} developed to address these issues. Further all these research work focus on providing better computational models to develop these systems encapsulating the communication complexity from the user as well.  However these researches have paid less attention to inter node communication efficiency. Therefore in this paper we focus on this inter node communication aspect and identify means of increasing throughput while keeping low latency levels.

First we started research on parallel TCP connections \cite{hacker2001end} to improve the performance since it has been used in wide area network applications. Although parallel TCP improves throughput of the system, we found that even without that it is possible to saturate the network link (1 Gbps link connected through a switch) with 256 byte array messages. However user APIs of the modern stream processing systems, deals with programming language objects rather than byte array messages. Therefore we can improve the performance of node communication by increasing the language level object to byte array conversion process. Further serialization form of these language objects (if proper serialization techniques used) can be small as well. Hence buffering programing level objects and serialize them as batches would greatly improve the performance. 

As a contribution of this paper we introduce those concepts and provide a reference implementation to compare with other frameworks and analyses the scalability and latency. These general concepts can be applied to any other software to improve its performance. 

The remainder of this paper is organized as follows: Section 2 provides an overview of our system at user level. Section 3 illustrates the underlying design of the system. Section 4 analyses the experiment results which demonstrate the performance of our solution. Section 5 discusses the related work and finally section 6 provides conclusions and future work.
